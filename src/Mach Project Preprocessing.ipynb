{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90dfadf7",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "After the EDA we can start to preprocess our data, which primarily includes splitting and encoding. \n",
    "\n",
    "### Rubric Questions\n",
    "Discuss how you split the dataset and why.\n",
    "\n",
    "Is your dataset IID? Does it have group structure?\n",
    "We know that the data is iid. By definition \"all samples stem from the same generative process and the generative process is assumed to have no memory of past generated samples.\" Here, this is the case. Also, we know that our data does not have group structure as well - \"data has group structure if samples are collected from different subjects, experiments, measurement devices\"\n",
    "\n",
    "Is it a time-series data?\n",
    "No. \n",
    "\n",
    "How should you split the dataset given your ML question to best mimic future use when you deploy the model?\n",
    "The goal here is to predict relationship status, so we need to include representatives of each relationship group in the training, validation, and test set. Otherwise, there are not other apparent classes or groups. \n",
    "\n",
    "How many features do you have in the preprocessed data?\n",
    "45 features and 1 target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd634167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#preprocessing tools\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2ae0b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Q1A', 'Q2A', 'Q3A', 'Q4A', 'Q5A', 'Q6A', 'Q7A', 'Q8A', 'Q9A', 'Q10A',\n",
      "       'Q11A', 'Q12A', 'Q13A', 'Q14A', 'Q15A', 'Q16A', 'Q17A', 'Q18A', 'Q19A',\n",
      "       'Q20A', 'testelapse', 'education', 'urban', 'gender', 'engnat', 'age',\n",
      "       'hand', 'religion', 'orientation', 'race', 'voted', 'married',\n",
      "       'familysize', 'major', 'marriedstr', 'Mscore', 'PITtime', 'NITtime',\n",
      "       'PVHtime', 'CVHtime', 'voc_fake', 'voc_conf', 'extraver', 'agreeable',\n",
      "       'conscient', 'neuroticism', 'openness'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1A</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q3A</th>\n",
       "      <th>Q4A</th>\n",
       "      <th>Q5A</th>\n",
       "      <th>Q6A</th>\n",
       "      <th>Q7A</th>\n",
       "      <th>Q8A</th>\n",
       "      <th>Q9A</th>\n",
       "      <th>Q10A</th>\n",
       "      <th>...</th>\n",
       "      <th>NITtime</th>\n",
       "      <th>PVHtime</th>\n",
       "      <th>CVHtime</th>\n",
       "      <th>voc_fake</th>\n",
       "      <th>voc_conf</th>\n",
       "      <th>extraver</th>\n",
       "      <th>agreeable</th>\n",
       "      <th>conscient</th>\n",
       "      <th>neuroticism</th>\n",
       "      <th>openness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6799.0</td>\n",
       "      <td>12788.0</td>\n",
       "      <td>7297.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7035.0</td>\n",
       "      <td>6411.0</td>\n",
       "      <td>7910.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8907.0</td>\n",
       "      <td>15823.0</td>\n",
       "      <td>6442.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8994.0</td>\n",
       "      <td>27609.0</td>\n",
       "      <td>6739.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12294.0</td>\n",
       "      <td>4149.0</td>\n",
       "      <td>8038.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1A  Q2A  Q3A  Q4A  Q5A  Q6A  Q7A  Q8A  Q9A  Q10A  ...  NITtime  PVHtime  \\\n",
       "0  2.0  4.0  4.0  5.0  5.0  5.0  3.0  2.0  2.0   4.0  ...   6799.0  12788.0   \n",
       "1  4.0  4.0  3.0  4.0  5.0  2.0  5.0  5.0  2.0   4.0  ...   7035.0   6411.0   \n",
       "2  4.0  2.0  3.0  2.0  4.0  2.0  4.0  1.0  2.0   2.0  ...   8907.0  15823.0   \n",
       "3  5.0  5.0  1.0  3.0  5.0  5.0  5.0  5.0  3.0   1.0  ...   8994.0  27609.0   \n",
       "4  2.0  4.0  2.0  2.0  2.0  2.0  4.0  4.0  1.0   2.0  ...  12294.0   4149.0   \n",
       "\n",
       "   CVHtime  voc_fake  voc_conf  extraver  agreeable  conscient  neuroticism  \\\n",
       "0   7297.0         1        11       8.0        7.0       11.0          7.0   \n",
       "1   7910.0         0        10       6.0       10.0        7.0          8.0   \n",
       "2   6442.0         0         8       6.0        6.0        8.0          7.0   \n",
       "3   6739.0         0         8       5.0        5.0        8.0         10.0   \n",
       "4   8038.0         0        10       9.0       10.0        7.0          5.0   \n",
       "\n",
       "   openness  \n",
       "0       6.0  \n",
       "1       6.0  \n",
       "2       4.0  \n",
       "3       2.0  \n",
       "4       5.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read in data set and print\n",
    "df = pd.read_csv('/users/ktoleary.13/Desktop/DATA1030_Proj/mach_rel_classification/data/data_edit1.csv', delimiter=',')\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8febf27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1A contains [2. 4. 5. 3. 1. 0.]\n",
      "Q2A contains [4. 2. 5. 1. 3. 0.]\n",
      "Q3A contains [ 4.  3.  1.  2.  5. nan]\n",
      "Q4A contains [ 5.  4.  2.  3.  1. nan]\n",
      "Q5A contains [5. 4. 2. 3. 1. 0.]\n",
      "Q6A contains [ 5.  2.  1.  4.  3. nan]\n",
      "Q7A contains [ 3.  5.  4.  1.  2. nan]\n",
      "Q8A contains [2. 5. 1. 4. 3. 0.]\n",
      "Q9A contains [ 2.  3.  1.  4.  5. nan]\n",
      "Q10A contains [ 4.  2.  1.  3.  5. nan]\n",
      "Q11A contains [ 5.  4.  3.  2.  1. nan]\n",
      "Q12A contains [5. 4. 2. 3. 1. 0.]\n",
      "Q13A contains [1. 4. 5. 2. 3. 0.]\n",
      "Q14A contains [ 5.  3.  4.  2.  1. nan]\n",
      "Q15A contains [4. 1. 5. 3. 2. 0.]\n",
      "Q16A contains [ 5.  4.  2.  1.  3. nan]\n",
      "Q17A contains [1. 2. 3. 4. 5. 0.]\n",
      "Q18A contains [5. 4. 1. 3. 2. 0.]\n",
      "Q19A contains [ 3.  1.  5.  2.  4. nan]\n",
      "Q20A contains [4. 2. 1. 5. 3. 0.]\n",
      "testelapse contains [ 191.  185.  230. ... 1441. 3574. 1572.]\n",
      "education contains [4 2 1 3 0]\n",
      "urban contains [3 1 2 0]\n",
      "gender contains [2 1 3 0]\n",
      "engnat contains [2 1 0]\n",
      "age contains [ 31  37  40  79  32  42  45  36  50  43  48  33  34  38  39  56  35  41\n",
      "  55  62  52  47  53  54  49  58  66  59  44  63  64  60  46  70  51  61\n",
      "  72  65  57  67  69  68  78  71  75  74  73  81  76  85  84  88  80  99\n",
      "  83  91  82  77  92 100  90  87 110]\n",
      "hand contains [1 2 3 0]\n",
      "religion contains [ 6  1 12  2  7  4  5  3  8 10  0  9 11]\n",
      "orientation contains [1 2 0 3 5 4]\n",
      "race contains [60 10 30 70  0 20 50 40]\n",
      "voted contains [1 2 0]\n",
      "married contains [3 1 2]\n",
      "familysize contains [ 2  1  3  0  5  4  6 10  8  9  7 15 12 11 13 14 17 16]\n",
      "major contains ['international relations' 'biology' nan ... 'pharmaceutical science '\n",
      " 'classica' 'chinese literature ']\n",
      "marriedstr contains ['previously married' 'never married' 'currently married']\n",
      "Mscore contains [ 74.  69.  57.  76.  56.  51.  66.  79.  78.  67.  41.  75.  37.  54.\n",
      "  63.  83.  68.  80.  60.  71.  40.  47.  73.  77.  65.  35.  61.  59.\n",
      "  85.  81.  32.  53.  30.  39.  92.  72.  46.  70.  84.  48.  33.  87.\n",
      "  64.  44.  45.  62.  42.  50.  88.  43.  52.  49.  58.  55.  86.  36.\n",
      "  89.  38.  25.  34.  96.  91.  82.  29.  28.  31.  95. 100.  90.  27.\n",
      "  26.  23.  94.  22.  24.  93.  21.   0.  20.]\n",
      "PITtime contains [ 4635.  4152.  4549. ... 31321.  8716. 13073.]\n",
      "NITtime contains [ 6799.  7035.  8907. ... 10357. 17587.  3821.]\n",
      "PVHtime contains [12788.  6411. 15823. ... 13214.  3309.  8839.]\n",
      "CVHtime contains [ 7297.  7910.  6442. ... 44758. 43280.  3260.]\n",
      "voc_fake contains [1 0 2 3]\n",
      "voc_conf contains [11 10  8 12  4  9 13  7 14 16  5  6  3  0 15  1  2]\n",
      "extraver contains [ 8.  6.  5.  9.  3. 11. 12.  7. 10.  4.  2. 13.  0. 14.  1.]\n",
      "agreeable contains [ 7. 10.  6.  5.  4.  3. 11.  9.  8. 12.  2. 13.  0. 14.  1.]\n",
      "conscient contains [11.  7.  8.  6.  3. 12.  9. 10. 13.  5.  4.  0. 14.  2.  1.]\n",
      "neuroticism contains [ 7.  8. 10.  5.  9.  3.  6. 12.  4. 11. 13.  2.  0.  1. 14.]\n",
      "openness contains [ 6.  4.  2.  5.  7.  8. 10. 11.  9. 12.  3.  0. 13.  1. 14.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(26043, 47)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get types of each column\n",
    "for name in list(df.columns):\n",
    "    print(name, \"contains\", df[name].unique())\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb6cf80",
   "metadata": {},
   "source": [
    "Most data is clean, but some of the individual questions for the surveys have NaNs. Because zero has no meaning on the likert-scale, we can convert these values to zero and establish a category for the missing values. This way, we can check if there is potential meaning in these missing values but wrap them in a more usable data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "835c391d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1A contains [2. 4. 5. 3. 1. 0.]\n",
      "Q2A contains [4. 2. 5. 1. 3. 0.]\n",
      "Q3A contains [4. 3. 1. 2. 5. 0.]\n",
      "Q4A contains [5. 4. 2. 3. 1. 0.]\n",
      "Q5A contains [5. 4. 2. 3. 1. 0.]\n",
      "Q6A contains [5. 2. 1. 4. 3. 0.]\n",
      "Q7A contains [3. 5. 4. 1. 2. 0.]\n",
      "Q8A contains [2. 5. 1. 4. 3. 0.]\n",
      "Q9A contains [2. 3. 1. 4. 5. 0.]\n",
      "Q10A contains [4. 2. 1. 3. 5. 0.]\n",
      "Q11A contains [5. 4. 3. 2. 1. 0.]\n",
      "Q12A contains [5. 4. 2. 3. 1. 0.]\n",
      "Q13A contains [1. 4. 5. 2. 3. 0.]\n",
      "Q14A contains [5. 3. 4. 2. 1. 0.]\n",
      "Q15A contains [4. 1. 5. 3. 2. 0.]\n",
      "Q16A contains [5. 4. 2. 1. 3. 0.]\n",
      "Q17A contains [1. 2. 3. 4. 5. 0.]\n",
      "Q18A contains [5. 4. 1. 3. 2. 0.]\n",
      "Q19A contains [3. 1. 5. 2. 4. 0.]\n",
      "Q20A contains [4. 2. 1. 5. 3. 0.]\n"
     ]
    }
   ],
   "source": [
    "#the tranformer doesnt like the NaNs, we'll turn these into zeros, which is also used in the married column\n",
    "mquestions = ['Q1A', 'Q2A', 'Q3A', 'Q4A', 'Q5A', 'Q6A', 'Q7A', 'Q8A', 'Q9A', 'Q10A','Q11A', 'Q12A', 'Q13A', 'Q14A', \\\n",
    "          'Q15A', 'Q16A', 'Q17A', 'Q18A', 'Q19A', 'Q20A']\n",
    "#Fill the nans with 0. This is the same encoding scheme for married col. Does not adjust the mscore at all\n",
    "for q in mquestions:\n",
    "    df[q] = df[q].fillna(0)\n",
    "\n",
    "#get types of each column\n",
    "for name in mquestions:\n",
    "    print(name, \"contains\", df[name].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22b11dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    12521\n",
       "1     8359\n",
       "3     5163\n",
       "Name: married, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DETERMINE ENCODERS\n",
    "#most everything is already encodeded and bounded in a range\n",
    "#categorical - questions that are answered on likert\n",
    "ord_ft = ['Q1A', 'Q2A', 'Q3A', 'Q4A', 'Q5A', 'Q6A', 'Q7A', 'Q8A', 'Q9A', 'Q10A','Q11A', 'Q12A', 'Q13A', 'Q14A', \\\n",
    "          'Q15A', 'Q16A', 'Q17A', 'Q18A', 'Q19A', 'Q20A','education', 'extraver', 'agreeable', 'conscient', 'neuroticism', 'openness']\n",
    "onehot_ft = ['race', 'voted','familysize', 'major','urban', 'gender', 'engnat', 'orientation','hand', 'religion','voc_fake', 'voc_conf']\n",
    "minmax_ft = ['Mscore', 'age']                \n",
    "stnd_ft = ['testelapse','PITtime', 'NITtime', 'PVHtime','CVHtime']    \n",
    "\n",
    "#0 are people who didn't answer\n",
    "df['married'].value_counts()\n",
    "# stratified K Fold to represent groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3390700",
   "metadata": {},
   "source": [
    "Once we've established the encoders, we can define our target variables, split the data, and finish preprocessing. Because there is a distinctive group structure in our target variable, I chose to do a stratified kfold split. That way, the train,validation, and testing sets will always have a representative of the target variable's categories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a7b0d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define X and y and encode\n",
    "y1 = df['married']\n",
    "X1 = df.loc[:, df.columns != 'married'] # all other columns are features    \n",
    "\n",
    "#set the random state\n",
    "random_state = 77\n",
    "\n",
    "# collect all the encoders\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ord', OrdinalEncoder(), ord_ft), #ord fts already in ascending, numeric order\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ft),\n",
    "        ('minmax', MinMaxScaler(), minmax_ft),\n",
    "        ('std', StandardScaler(), stnd_ft)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03905acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train balance:\n",
      "2    0.480785\n",
      "1    0.320984\n",
      "3    0.198231\n",
      "Name: married, dtype: float64\n",
      "val balance:\n",
      "2    0.461857\n",
      "1    0.338585\n",
      "3    0.199558\n",
      "Name: married, dtype: float64\n",
      "train balance:\n",
      "2    0.480785\n",
      "1    0.320984\n",
      "3    0.198231\n",
      "Name: married, dtype: float64\n",
      "val balance:\n",
      "2    0.455777\n",
      "1    0.342454\n",
      "3    0.201769\n",
      "Name: married, dtype: float64\n",
      "train balance:\n",
      "2    0.480785\n",
      "1    0.320984\n",
      "3    0.198231\n",
      "Name: married, dtype: float64\n",
      "val balance:\n",
      "2    0.455777\n",
      "1    0.339690\n",
      "3    0.204533\n",
      "Name: married, dtype: float64\n",
      "train balance:\n",
      "2    0.480809\n",
      "1    0.320923\n",
      "3    0.198268\n",
      "Name: married, dtype: float64\n",
      "val balance:\n",
      "2    0.463920\n",
      "1    0.335361\n",
      "3    0.200719\n",
      "Name: married, dtype: float64\n",
      "train balance:\n",
      "2    0.480763\n",
      "1    0.320969\n",
      "3    0.198268\n",
      "Name: married, dtype: float64\n",
      "val balance:\n",
      "2    0.461156\n",
      "1    0.328725\n",
      "3    0.210119\n",
      "Name: married, dtype: float64\n",
      "train balance:\n",
      "2    0.480763\n",
      "1    0.320969\n",
      "3    0.198268\n",
      "Name: married, dtype: float64\n",
      "val balance:\n",
      "2    0.463091\n",
      "1    0.335361\n",
      "3    0.201548\n",
      "Name: married, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Split first and then preprocess second\n",
    "# do KFold split on other\n",
    "kf = StratifiedKFold(n_splits=6,shuffle=True,random_state=random_state) \n",
    "#include shuffle so that young ages aren't overrepresented\n",
    "for train_index, other_index in kf.split(X1,y1):\n",
    "    X1_train = X1.iloc[train_index]\n",
    "    y1_train = y1.iloc[train_index]\n",
    "    X1_other = X1.iloc[other_index]\n",
    "    y1_other = y1.iloc[other_index]\n",
    "    #create another stratified fold split for validation and test set\n",
    "    for val_index, test_index in kf.split(X1_other,y1_other):\n",
    "        X1_val = X1.iloc[val_index]\n",
    "        y1_val = y1.iloc[val_index]\n",
    "        X1_test = X1.iloc[test_index]\n",
    "        y1_test = y1.iloc[test_index]\n",
    "    print('train balance:')\n",
    "    print(y1_train.value_counts(normalize=True))\n",
    "    print('val balance:')\n",
    "    print(y1_val.value_counts(normalize=True))\n",
    "    #apply transformer\n",
    "    X_train_prep = clf.fit_transform(X1_train)\n",
    "    X_val_prep = clf.transform(X1_val)\n",
    "    X_test_prep = clf.transform(X1_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
